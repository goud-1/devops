k8s installation:
=================
minikube installation:

sudo apt update -y
sudo apt upgrade -y
sudo apt install curl wget apt-transport-https -y
sudo curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo mv minikube-linux-amd64 /usr/local/bin/minikube
sudo chmod +x /usr/local/bin/minikube
sudo minikube version
sudo curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo curl -LO "https://dl.k8s.io/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256"
sudo echo "$(cat kubectl.sha256) kubectl" | sha256sum --check
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
sudo minikube start --driver=docker --force
 
 pod: 
 pod is the basic scheduling unit. 
 POD: Group of containers
 It is a group of one or more containers that are deployed together on the same host
 pods are considered to be ephemeral(short living objeccts)
 Keep in mind that while pods are the basic unit of scheduling, it's common to manage 
 them using higher-level abstractions like Deployments or StatefulSets, which provide 
 additional features such as automatic scaling, rolling updates, and more.
 it is the smallest unit of K8s that can be deployable.
 inside pod we have container 
 inside container we have application.

POD CAN BE CREATED ON 2 WAYS.

1. IMPERTAIVE: commands.
2. DECLARATIVE: Manifest file.
 
 pods can be created two ways 
 1.imparative method
 2.declarative method
 
 
1.imparative method:

kubectl run pod1 --image=ramu478/devops
kubectl get pods
kubectl get po -o wide	
kubectl descirbe pod pod1
kubectl delete pod pod1

declarative method:

vim pod2.yml
apiVersion: v1
kind: Pod
metadata:
  name: pod2 
spec:
  containers:
    - image: ramu478/devops
      name: cont1
	  
kubectl apply -f pod2.yml

Replicaset:
a ReplicaSet is a controller that ensures a specified number of identical pods 
are running at all times
It is part of the Kubernetes API, and its purpose is to maintain the desired number
of pod replicas in a system.  
	  
vim replicaset.yml

apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: ramesh-replicaset
spec:
  replicas: 3
  selector:
    matchLabels:
      app: pod1
  template:
    metadata:
      labels:
        app: pod1
    spec:
      containers:
      - name: cont2
        image: ramu478/aws

kubectl apply -f replicaset.yml
kubectl get rs/replicaset
kubectl get rs -o wide
kubectl describe rs example-replicaset
kubectl delete rs example-replicaset
kubectl get pods -l app=example

deployment:
we can update the application 

vim deployment.yml
 
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: pod2
  name: pod2-rs
spec:
  replicas: 3
  selector:
    matchLabels:
      app: pod2
  template:
    metadata:
      labels:
        app: pod2
    spec:
      containers:
      - name: cont2
        image: ramu478/java

kubectl get deploy
kubectl get deploy -o wide
kubectl describe deploy name-of-deployment
kubectl delete deploy name-of-deploy
kubectl get pods -l app=swiggy
kubectl scale deploy/name-of-deploy --replicas=10 (LIFO)
kubectl edit deploy/name-of-deploy
kubectl get pods --show-labels
history:
    vim minikube.sh
    2  sh minikube.sh
    3  minikube status
    4  kubectl get nodes
    5  kubectl get pods
    6  kubectl run pod1 --image=ramu478/java
    7  kubectl get pods
    8  docker --version
    9  kubectl get po
   10  kubectl get po -o wide
   11  kubectl describe pod1
   12  kubectl describe pod pod1
   13  kubectl delete pod pod1
   14  kubectl get pods
   15  kubectl run pod1 --image=rameshmekala123/database
   16  kubectl get po
   17  kubectl run pod2 --image=rameshmekala123/aws
   18  kubectl get po
   19  kubectl run pod2 --image=nginx
   20  kubectl run pod3 --image=nginx
   21  kubectl get po
   22  kubectl delete pod pod1
   23  kubectl delete pod pod2
   24  vim pod1.yml
   25  kubectl apply -f pod1.yml
   26  kubectl get pods
   27  kubectl delete pod pod1
   28  kubectl delete pod pod3
   29  vim pod1.yml
   30  kubectl apply -f pod1.yml
   31  kubectl get po
   32  kubectl get po -o wide
   33  kubectl describe pod pod1
   34  kubectl delete pod pod1
   35  vim replicaset.yml
   36  kubectl apply -f replicaset.yml
   37  kubectl get rs
   38  kubectl get rs -o wide
   39  kubectl describe rs ramesh-replicaset
   40  kubectl get po
   41  vim deployment.yml
   42  kubectl apply -f deployment.yml
   43  kubectl get deploy
   44  kubectl get deploy -o wide
   45  kubectl describe deploy pod2-rs
   46  kubectl get po
   47  kubectl delete rs ramesh-replicaset-8qzs5
   48  kubectl delete pod ramesh-replicaset-8qzs5
   49  kubectl get po
   50  kubectl get rs
   51  kubectl delete rs ramesh-replicaset
   52  kubectl get po
   53  kubectl get deploy
   54  kubectl delete deploy pod2-rs
   55  kubectl get po


to start the minikube we have to use the following command

minikube start --driver=docker --force
========================================================================================================================
kops installation:
==================
kOps, also known as Kubernetes operations, is an open-source tool that helps you create, destroy, upgrade, and maintain a highly available, production-grade Kubernetes cluster. Depending on the requirement, kOps can also provision cloud infrastructure.
kOps is mostly used in deploying AWS and GCE Kubernetes clusters. But officially, the tool only supports AWS. Support for other cloud providers (such as DigitalOcean, GCP, and OpenStack) are in the beta stage.

ADVANTAGES:
•	Automates the provisioning of AWS and GCE Kubernetes clusters
•	Deploys highly available Kubernetes masters
•	Supports rolling cluster updates
•	Autocompletion of commands in the command line
•	Generates Terraform and CloudFormation configurations
•	Manages cluster add-ons.
•	Supports state-sync model for dry-runs and automatic idempotency
•	Creates instance groups to support heterogeneous clusters
ALTERNATIVES:
Amazon EKS , MINIKUBE, KUBEADM, RANCHER, TERRAFORM, HELM.

IAM KEYS: Used to provide access for the kops to create infra.

IAM -- > USERS -- > ADD USERS -- > NAME: kops  -- > NEXT -- > Set permissions: Set permission -- > AdministratorAccess -- > next -- > create
users -- > security credentials -- > create Access keys -- > CLI -- > NEXT -- > CREATE ACCESS KEYS

STEP-1:
ATTACHING KOPS PERMISSIONS TO EC2:
aws configure
cd .aws 
ll
vim config
vim credentials

STEP-2: DOWNLOAD KOPS & KUBECTL 
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
wget https://github.com/kubernetes/kops/releases/download/v1.24.1/kops-linux-amd64
chmod +x kops-linux-amd64 kubectl  # to provide executable permission of both files
mv kubectl /usr/local/bin/kubectl  # all the user executed commands will be on bin folder
mv kops-linux-amd64  /usr/local/bin/kops
vim .bashrc
export PATH=$PATH:/usr/local/bin/
source .bashrc

STEP-3: CREATING BUCKET (To store cluster information) bucket is an object-level store.
aws s3api create-bucket --bucket ramu123321.k8s --region us-east-1
aws s3api put-bucket-versioning --bucket ramu123321.k8s --region us-east-1 --versioning-configuration Status=Enabled
export KOPS_STATE_STORE=s3://ramu123321.k8s

STEP-4: CREATING CLUSTER
kops create cluster --name mohamk8s --zones us-east-1a  --master-size t2.medium --node-size t2.micro
kops update cluster --name mohank8s --yes --admin

kops delete cluster --name ramu123321.k8s --yes

history:
 1  yum update -y
    2  aws configure
    3  vim .bashrc
    4  source .bashrc
    5  curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
    6  wget https://github.com/kubernetes/kops/releases/download/v1.24.1/kops-linux-amd64
    7  chmod +x kops-linux-amd64 kubectl  # to provide executable permission of both files
    8  mv kubectl /usr/local/bin/kubectl  # all the user executed commands will be on bin folder
    9  mv kops-linux-amd64  /usr/local/bin/kops
   10  aws s3api create-bucket --bucket ramu123321.k8s --region us-east-1
   11  aws s3api put-bucket-versioning --bucket ramu123321.k8s --region us-east-1 --versioning-configuration Status=Enabled
   12  export KOPS_STATE_STORE=s3://ramu123321.k8s
   13  kops create cluster --name mohamk8s --zones us-east-1a  --master-size t2.medium --node-size t2.micro
   14  kops create cluster --name mohan.k8s.local --zones us-east-1a  --master-size t2.medium --node-size t2.micro
   15  kops get cluster
   16   kops update cluster --name mohan.k8s.local --yes --admin
   17  kubectl get nodes --show-labels
   18  kops validate cluster --wait 10m
   19  kubectl get nodes
   20  kubectl run pod1 --image ramu478/java
   21  kubectl get po
   22  kubectl get po -o wide
   23  kubectl describe pod pod1
   24  vim pod2.yml
   25  kubectl apply -f pod2.yml
   26  kubectl get po
   27  kops delete cluster --name mohan.k8s.local --yes
=========================================================================================================================
vim .bashrc
export PATH=$PATH:/usr/local/bin/
source .bashrc

vim kops.sh
aws configure
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
wget https://github.com/kubernetes/kops/releases/download/v1.24.1/kops-linux-amd64
chmod +x kops-linux-amd64 kubectl  # to provide executable permission of both files
mv kubectl /usr/local/bin/kubectl  # all the user executed commands will be on bin folder
mv kops-linux-amd64  /usr/local/bin/kops
aws s3api create-bucket --bucket ramu123321.k8s --region us-east-1
aws s3api put-bucket-versioning --bucket ramu123321.k8s --region us-east-1 --versioning-configuration Status=Enabled
export KOPS_STATE_STORE=s3://ramu123321.k8s
kops create cluster --name mohan.k8s.local --zones us-east-1a --master-count=1 --master-size t2.medium --node-count=2 --node-size t2.micro
kops update cluster --name mohan.k8s.local --yes --admin

sh kops.sh

clusterIP: it can provide internal communication between pods
kind: Deployment
metadata:
  labels:
    app: aws
  name: aws-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: aws
  template:
    metadata:
      labels:
        app: aws
    spec:
      containers:
      - name: cont1
        image: ramu478/aws
        ports:
          - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: ram
spec:
  type: ClusterIP
  selector:
    app: aws
  ports:
    - port: 80

nodeport:
=========
it is used expose service to outside environment
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: aws
  name: aws1-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: aws
  template:
    metadata:
      labels:
        app: aws
    spec:
      containers:
      - name: cont1
        image: ramu478/aws
        ports:
          - containerPort: 80

---
apiVersion: v1
kind: Service
metadata:
  name: kranthi
spec:
  type: NodePort
  selector:
    app: aws
  ports:
    - port: 80
      targetPort: 80
      nodePort: 31111

SCALING THE NODES:
kops edit ig --name=mohan.k8s.local nodes-us-east-1a
kops update cluster --name mohan.k8s.local --yes --admin
kops rolling-update cluster

history:
 1  yum update -y
    2  aws configure
    3  vim .bashrc
    4  source .bashrc
    5  vim kops.sh
    6  sh kops.sh
    7  kops validate cluster
    8  cat kops.sh
    9  export KOPS_STATE_STORE=s3://ramu123321.k8s
   10  kops validate cluster
   11  kubectl get nodes
   12  kubectl run pod1 --image ramu478/aws
   13  kubectl get po
   14  kubectl get po -o wide
   15  vim service.yml
   16  kubectl apply -f service.yml
   17  kubectl get svc
   18  kubectl get deploy
   19  kubctl get po
   20  kubectl get po
   21  kubectl get po -o wide
   22  ping 54.226.4.194
   23  kubectl get svc
   24  vim nodeport.yml
   25  kubectl apply -f nodeport.yml
   26  kubectl get svc
   27  kubectl get po -o wide
   28  kops delete cluster --name mohan.k8s.local --yes
======================================================================================================================
loadbalancer:
=============
vim loadbalancer.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: aws
  name: aws-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: aws
  template:
    metadata:
      labels:
        app: aws
    spec:
      containers:
      - name: cont1
        image: ramu478/aws
        ports:
          - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: ramu
spec:
  type: LoadBalancer
  selector:
    app: aws
  ports:
    - port: 80
      targetPort: 80

kubectl apply -f load balancer.yml

NOTE: we must setup the security groups to all traffic to nodes after creating the cluster.

NAMESPACE:
----------
 namespace is nothing but cluster with in the cluster.it will provide the isolated environment.
types of namespaces:
--------------------
1.default namespace :all objects will create here only
2.kube-node-lease name space:it will store object from one name space to another nameapace
3.kube public name space:all public objects will store here
4.kubesystem namespace: default k8s will create some objects, 
                         those are storing on this ns.
						 
kubectl get pod -n namesystemname :list of pods in the name space
kubectl get po -A :all pods in all nodes

kubectl create ns dev	
kubectl config set-context --current --namespace=dev
kubectl config view --minify | grep namespace
kubectl delete ns dev
kubectl delete pod --all

history:
-------
 cat kops.sh
   59  sh kops.sh
   60  kubectl get nodes
   61  ls
   62  vim loadbalancer.yml
   63  kubectl apply -f loadbalancer.yml
   64  kubectl get svc
   65  kubectl get po
   66  kubectl get po -o wide
   67  kubectl get svc
   68  kubectl get ns
   69  kubectl get po
   70  kubectl get svc
   71  kubectl delete svc ramu
   72  kubectl get po
   73  kubectl get svc
   74  kubectl delete pod --all
   75  kubectl get po
   76  cat loadbalancer.yml
   77  kubectl get deploy
   78  kubectl delete  deploy aws-deploy
   79  kubectl get po
   80  kubectl get ns
   81  kubectl get po -n default
   82  kubectl run --image ramu478/aws
   83  kubectl run pod1 --image ramu478/aws
   84  kubectl get po
   85  kubectl get po -n default
   86  kubectl get po -n kube-node-lease
   87  kubectl get po -n kube-public
   88  kubectl get po -n kube-system
   89  kubectl get po -A
   90  kubectl create ns test
   91  kubectl get ns
   92  kubectl config --minify
   93  kubectl config minify
   94  kubectl config -minify
   95  kubectl config view --minify
   96  kubectl config view --minify | grep namespace
   97  kubectl config set-context --current --namespace=test
   98  kubectl config view --minify | grep namespace
   99  kubectl run pod2 --image nginx
  100  kubectl get po -o wide
  101  kubectl delete ns test
  102  kubectl get po
  103  kubectl config view --minify | grep namespace
  104  kubectl get ns
  105  kubectl config set-context --current --namespace=default
  106  kubectl create  ns dev
  107  kubectl config set-context --current --namespace=dev
  108  kubectl config view --minify
  109  kubectl config view --minify | grep namespace
  110  vim pod.yml
  111  kubectl appy -f pod.yml
  112  kubectl apply -f pod.yml
  113  kubectl appy -f pod.yml
  114  vim pod.yml
  115  kubectl appy -f pod.yml
  116  kubectl apply -f pod.yml
  117  kops delete cluster --name mohan.k8s.local --yes
  118  cat kops.sh
  119  export KOPS_STATE_STORE=s3://ramu123321.k8s
  120  kops delete cluster --name mohan.k8s.local --yes
========================================================================================================================
configmaps and secrets:
----------------------
--> a config map is an API object used to store configuration data that can be 
   consumed by pods or other resources in the cluster
 -->it provides a way to decouple configuration settings from containerized
   applications,making it easier to manage and update configuration data 
   without modifying the application code or container images
-->configmaps store key-value pairs or provide the mount configuration 
   files as data 
-->this can include environment variables,commandline  arguments,
   configuration files or any other type of configuration data required by 
   your application. 
secrets:
--------
In k8s, a secret is an API object used to store sensitive information,such as passwords,tokens or SSH keys 
-->secrets provide a way to securely store and manage sensitive data with in a cluster
--->secrrets can be used by applications and pods to access sensitive information without exposing it in plain text
-->they are typically used to store data that needs to be passed containers securely,such as database credentials,API keys etc 
-->kubernetes secrets stored in the cluster's etcd datastore,encrypted at rest. they can be accessed by pods or other kubernetes objects securely

vim configmap.yml

apiVersion: v1
kind: ConfigMap
metadata:
  name: devopscm
data:
  tomcat_url: "https://172.26.150.100:8080"
  db_url: "https://172.35.14.105:5432"

vim pod.yml 

apiVersion: v1
kind: Pod
metadata:
  name: devops
spec:
  containers:
    - name: devops-cont1
      image: nginx
      envFrom:
        - configMapRef:
            name: devopscm
kubectl apply -f configmap.yml
kubectl apply -f pod.yml
kubectl describe cm swiggycm
kubectl describe pod swiggy

file formate:

vim varsfile
MYSQL_ROOT_PASSWORD=ramu
MYSQL_USER=admin

kubectl create cm dbvars --from-env-file=varsfile
kubectl describe cm dbvars
kubectl get cm
kubectl get pods

SECRETS:

To store sensitive data in an unencrypted format like passwords, ssh-keys etc ---
it uses base64 encoded format
Designed to prevent  exposure or unauthorized access to sensitive information within the cluster.
Both secrets and Config maps are used outside of deployment
config maps cannot encode but secrets will encode the data
password=ram (now we can encode and ecode the value)
kubectl get secret
kubectl create secret generic password --from-literal=ROOT_PASSWORD=ram123
kubectl get secrets

history:
mkdir kubernetes
  165  cd kubernetes/
  166  vim configmaps.yml
  167  vim pod.yml
  168  kubectl apply -f configmaps.yml
  169  kubectl apply -f pod.yml
  170  kubectl get pods
  171  kubectl get po -o wide
  172  kubectl describe cm devopscm
  173  cat pod.yml
  174  vim varsfile
  175  kubectl create cm dbvars --from-env-file=varsfile
  176  kubectl describe cm dbvars
  177  kubectl get deploy
  178  kubectl create deploy swiggydb --image=mariadb
  179  kubectl get deploy
  180  kubectl get pod
  181  kubectl get deploy
  182  kubectl create secret generic password --from-literal=ROOT_PASSWORD=ram123
  183  kubectl get secrets
  184  kubectl describe secret
  185  kops delete cluster --name mohan.k8s.local --yes
  186  cd ..
  187  cat kops.sh
  188  export KOPS_STATE_STORE=s3://ramu123321.k8s
  189  kops delete cluster --name mohan.k8s.local --yes


